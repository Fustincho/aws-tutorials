{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bd14be-1443-4147-b0cc-52ec6cc1bbd0",
   "metadata": {},
   "source": [
    "# Building and Pushing Custom Docker Images to Amazon ECR\n",
    "\n",
    "In the first notebook, we will focus on the process of creating a custom Docker image. This will involve selecting a base image, installing necessary dependencies, and configuring the environment to suit your specific ML requirements. We'll then guide you through the process of pushing this custom image to Amazon Elastic Container Registry (ECR), a fully managed Docker container registry that makes it easy to store, manage, share, and deploy your container images.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-images.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb80d26-3304-4a35-b2d7-667cf8989504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd7416c-d1d0-4352-9ca5-e73d6babf655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f069d3d-6a61-408a-92bb-e48b493620a0",
   "metadata": {},
   "source": [
    "## Creating Requirements Files for Custom Environments\n",
    "\n",
    "We create two distinct requirements files, each tailored for a specific custom environment in our Docker container. These files list the Python libraries that will be installed in each environment.\n",
    "\n",
    "To create these files, we use the `%%writefile` magic command in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cd4026-15fa-43cb-a8d9-13d753003ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing container/requirements_env1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/requirements_env1.txt\n",
    "Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd90f856-ea7c-49b5-8f4e-0af16c1e220b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing container/requirements_env2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/requirements_env2.txt\n",
    "matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75911cc4-6e44-4614-8e0e-840e251fa8f0",
   "metadata": {},
   "source": [
    "## Constructing the Dockerfile for Custom Environments\n",
    "\n",
    "This section involves creating a [Dockerfile](https://docs.docker.com/engine/reference/builder/#dockerfile-reference) to define the custom Docker image. This Dockerfile is based on the official Python 3.11 image and includes the setup for two distinct Python virtual environments. These environments correspond to the two sets of requirements we defined earlier.\n",
    "\n",
    "> In this Dockerfile, we emphasize the installation and configuration of **ipykernel** in each virtual environment. This step is crucial because Amazon SageMaker Studio utilizes these kernels to interface with the Docker image. When SageMaker Studio users select a custom image for their Jupyter notebooks, it identifies the available Python environments through these kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1853b1af-8fe9-4238-8a6a-50c27d22eaf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing container/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/Dockerfile\n",
    "FROM python:3.11 as base\n",
    "\n",
    "# Create virtual environments\n",
    "RUN python3 -m venv /env1\n",
    "RUN python3 -m venv /env2\n",
    "\n",
    "# Environment 1 setup\n",
    "COPY requirements_env1.txt /\n",
    "RUN /env1/bin/pip install --no-cache-dir ipykernel\n",
    "RUN /env1/bin/pip install -r /requirements_env1.txt\n",
    "RUN /env1/bin/python -m ipykernel install --name=env1 --display-name \"Python 3.11 [pip env: Faker]\"\n",
    "\n",
    "# Environment 2 setup\n",
    "COPY requirements_env2.txt /\n",
    "RUN /env2/bin/pip install --no-cache-dir ipykernel\n",
    "RUN /env2/bin/pip install -r /requirements_env2.txt\n",
    "RUN /env2/bin/python -m ipykernel install --name=env2 --display-name \"Python 3.11 [pip env: matplotlib]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2ec19-f197-4ae4-b429-3fcd3301db44",
   "metadata": {},
   "source": [
    "To maintain the efficiency and cleanliness of your Docker environment, it's important to occasionally remove unused Docker objects. This is where the command `!docker system prune -af` comes into play.\n",
    "\n",
    "+ `docker system prune``: This command removes unused Docker objects, such as containers, networks, images (both dangling and unreferenced), and optionally, volumes.\n",
    "+ `-a` or `--all`: This flag removes all unused images, not just dangling ones.\n",
    "+ `-f` or `--force`: This automatically confirms the removal without prompting for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f6510-dfa3-4c08-9d8a-c236fe3a36aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker system prune -af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef80a7-49d5-4644-8c0e-2e011d8f79e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following script builds a Docker image from the Dockerfile and pushes it to Amazon ECR.\n",
    "\n",
    "**Script Breakdown**\n",
    "\n",
    "1. Setting Parameters: The script sets the repository and image names, and identifies the AWS region and account ID to construct the full name of the ECR repository.\n",
    "\n",
    "2. Checking for ECR Repository: It checks if the specified ECR repository exists. If not, it creates a new repository.\n",
    "\n",
    "3. ECR Login: The script logs into ECR using aws ecr get-login-password, which is necessary for pushing images to the repository.\n",
    "\n",
    "4. Building the Docker Image: The Docker image is built from the Dockerfile located in the container directory. The image is tagged with both a simple name and the full ECR repository name.\n",
    "\n",
    "5. Pushing to ECR: Finally, the script pushes the Docker image to the ECR repository.\n",
    "\n",
    "Before proceeding with building and pushing Docker images to Amazon ECR, ensure you have an IAM role with the appropriate permissions for ECR operations. This role should include a policy that allows actions related to managing and uploading images to your ECR repository:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"ecr:BatchCheckLayerAvailability\",\n",
    "                \"ecr:BatchGetImage\",\n",
    "                \"ecr:CompleteLayerUpload\",\n",
    "                \"ecr:GetDownloadUrlForLayer\",\n",
    "                \"ecr:InitiateLayerUpload\",\n",
    "                \"ecr:PutImage\",\n",
    "                \"ecr:UploadLayerPart\",\n",
    "                \"ecr:ListImages\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:ecr:region:account_id:repository/sagemaker-custom-images\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c74137-95e7-4d22-a65f-14b0a0622864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cd container\n",
    "\n",
    "# Parameters\n",
    "REPO_NAME=sagemaker-custom-images\n",
    "IMAGE_NAME=test-image\n",
    "\n",
    "# Region, defaults to us-east-1\n",
    "REGION=$(aws configure get region)\n",
    "REGION=${REGION:-us-east-1}\n",
    "\n",
    "ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n",
    "FULL_NAME=\"${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/${REPO_NAME}:${IMAGE_NAME}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${REPO_NAME}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${REPO_NAME}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Login to ECR\n",
    "aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${FULL_NAME}\n",
    "\n",
    "# Build and push the image\n",
    "docker build . -t ${IMAGE_NAME} -t ${FULL_NAME}\n",
    "\n",
    "docker push ${FULL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe3857-2820-4405-98bc-722d0a3b0c3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you have successfully completed all the steps, your image should now be available in your ECR repository.\n",
    "\n",
    "![Image in ECR](img/ecr_image.png \"Image in ECR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103d60d-6e03-4c00-8346-d2f72d4009b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
