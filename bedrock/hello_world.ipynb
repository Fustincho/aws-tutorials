{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862b3417-4c81-4c1a-a75e-9d512158f5fd",
   "metadata": {},
   "source": [
    "# Hello, Amazon Bedrock!\n",
    "\n",
    "In this tutorial, we'll walk through a straightforward example of using Amazon Bedrock to access and invoke the [Llama2 13B Chat](https://llama.meta.com/llama2) model, covering model activation, permission setup, and model invocation in concise steps.\n",
    "\n",
    "To leverage models from Amazon Bedrock, users need to fulfill three key requirements. \n",
    "\n",
    "1. Activate the desired model by requesting access on the [Amazon Bedrock](https://aws.amazon.com/bedrock/) service page. This step ensures that the user has permission to use the model within the AWS ecosystem.\n",
    "2. Get the modelId of the activated model. Each model within Amazon Bedrock is identified by a unique modelId. For instance, if you're interested in using the base model of Llama 2 Chat 13B, the modelId would be `meta.llama2-13b-chat-v1`. This identifier is crucial for specifying the exact model you wish to invoke and is used in conjunction with the execution role to gain access to and utilize the model's capabilities.\n",
    "3. The app or the user must have an execution role with the appropriate permissions to invoke the model. Attach an IAM policy that grants the `bedrock:InvokeModel` action, specifying the resource with the model's Amazon Resource Name (ARN) in the format `arn:aws:bedrock:{AWS_REGION}::foundation-model/{MODEL_ID}`. Here's an example of such a policy:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock:InvokeModel\",\n",
    "            \"Resource\": \"arn:aws:bedrock:{AWS_REGION}::foundation-model/{MODEL_ID}\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecc15ba-5cd7-4a36-b988-0aea56b911cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "body = {\n",
    "    \"prompt\": \"Finish this song and don't include anything else: What is love (love)?\",\n",
    "    \"max_gen_len\": 512,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}\n",
    "\n",
    "response = client.invoke_model(\n",
    "    body=json.dumps(body),\n",
    "    modelId=\"meta.llama2-13b-chat-v1\",\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d612dc7a-de6e-4b0f-acf5-75696bd15946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Baby don't hurt me, don't hurt me, no more.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body['generation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca81ef9-648f-49e0-abe2-be21d21a36ef",
   "metadata": {},
   "source": [
    "From the [official documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-meta.html):\n",
    "\n",
    "The Meta Llama 2 Chat and LLama 2 models supports the following parameters to control randomness and diversity in the response, as well as the response length:\n",
    "\n",
    "- Temperature (`temperature`) – Use a lower value to decrease randomness in the response.\n",
    "\n",
    "- Top P (`top_p`) – Use a lower value to ignore less probable options. Set to 0 or 1.0 to disable.\n",
    "\n",
    "- Maximum length (`max_gen_len`) – Specify the maximum number of tokens to use in the generated response. The model truncates the response once the generated text exceeds max_gen_len.\n",
    "\n",
    "**Make sure to check the [pricing of the models here](https://aws.amazon.com/bedrock/pricing/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90001760-ca22-4557-acdb-3c33b310a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
