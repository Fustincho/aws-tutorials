{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b3ce77-766c-4f3d-b0eb-30ffaa7e6154",
   "metadata": {},
   "source": [
    "# Introduction to Training and Deploying Models with Amazon SageMaker\n",
    "\n",
    "This unit provides a comprehensive introduction to training and deploying machine learning models using Amazon SageMaker. Here's a summary of the key concepts and steps covered in this unit:\n",
    "\n",
    "- Setting Up SageMaker Resources\n",
    "- Preparing Data\n",
    "- Configuring the Estimator\n",
    "- Training the Model\n",
    "- Deploying the Model\n",
    "- Endpoint Management\n",
    "\n",
    "Throughout the unit, the focus is on keeping the data simple to concentrate on the tools and processes involved in model training and deployment with Amazon SageMaker. The unit aims to equip learners with the foundational skills needed to leverage SageMaker for efficient and scalable machine learning tasks, from data preparation to model deployment and management.\n",
    "\n",
    "The Iris dataset is selected for training in this example due to its simplicity and the clarity it provides in demonstrating machine learning concepts. It's a widely recognized toy dataset, ideal for focusing on the functionality and capabilities of the tools available in Amazon SageMaker without the complexity of larger datasets. This choice allows for an emphasis on the process and techniques of machine learning, rather than the intricacies of data preprocessing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e09a8b-bf2a-40f1-8519-e7729c1fb01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import get_secret\n",
    "from utils.toy_datasets import upload_dataset_to_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d535550f-8d97-412f-bc44-0081a4d8b713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded to S3 successfully.\n",
      "Cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "s3_bucket_uri = get_secret('s3_bucket_uri')\n",
    "s3_bucket_name = get_secret('s3_bucket_name')\n",
    "\n",
    "dataset_name = 'iris'\n",
    "upload_dataset_to_s3(dataset_name, s3_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c217b2-7beb-47c9-91c7-9797b0505b79",
   "metadata": {},
   "source": [
    "`sagemaker.Session()` initializes a new Amazon SageMaker session. This session acts as the **main interface for managing interactions with the Amazon SageMaker environment and AWS services**. It encapsulates the configuration and state for the operations you perform in SageMaker, such as training models, deploying endpoints, and accessing data in S3. By creating a SageMaker session, you gain a structured way to manage resources and execute SageMaker tasks within a specific AWS context, leveraging SageMaker's capabilities and services efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f637ebc1-c9c1-41bf-8941-ce2b4061b7db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_secret('role_arn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128051e8-5cd2-40ce-909e-cc1b7cd8746f",
   "metadata": {},
   "source": [
    "As its name indicates, `sagemaker.image_uris.retrieve` pulls the Docker image URI containing the XGBoost model. This URI points to a pre-built image that allows for the deployment or training of machine learning models using XGBoost. It's important to note that SageMaker offers a variety of [other model images](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-images.html) as well, which can be found and retrieved in a similar manner.\n",
    "\n",
    "Not all versions of a model are available in every AWS region. Availability can vary, and Amazon SageMaker provides [documentation](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/image_uri_config/xgboost.json) that lists which versions of models are accessible in which regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfc02bb-599e-4077-a7e8-da0fa4614249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve('xgboost', region='us-east-1', version='1.5-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb16a6c-3348-4fb4-bf2d-eda99251dccd",
   "metadata": {},
   "source": [
    "The `Estimator` object in Amazon SageMaker is a high-level interface designed to handle the deployment of models for training and prediction. In this snippet, an Estimator is created for the purpose of training a machine learning model, with several key parameters specified to configure the training environment:\n",
    "\n",
    "- `image_uri` specifies the Docker container image containing the model algorithm, in this case, an XGBoost model.\n",
    "- `role` is the AWS IAM role that SageMaker assumes to perform tasks on your behalf, such as accessing data in S3.\n",
    "- `instance_count=1` indicates that one instance will be used for the training job, suitable for handling the Iris dataset's size.\n",
    "- `instance_type=\"ml.m5.large\"` defines the type of computing instance to use, balancing cost and computational capability for the task.\n",
    "- `output_path` sets the S3 location where the trained model artifacts will be stored.\n",
    "- `sagemaker_session` links the estimator to the current SageMaker session, facilitating access to AWS resources and management of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd82954-ce54-423f-9e7c-824123ac372d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055397f-8d52-4651-b8c5-4b6acf6ab931",
   "metadata": {},
   "source": [
    "[Here](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) is the list of hyperparameters that can be configured for the XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0487b0-e7b4-4c49-b024-ec6112b7fc57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    num_round=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a5e56-576b-4570-bc73-f38ebcacf969",
   "metadata": {},
   "source": [
    "The `TrainingInput` class is used to specify the location and format of the data stored in S3. This is important for informing SageMaker about where to find the data and how to interpret it during the training process.\n",
    "\n",
    "*In the context of preparing data for training with Amazon SageMaker, it's important to note that, by default, SageMaker expects the target variable (or label) to be in the **first column** of the dataset. This convention applies when using built-in algorithms provided by SageMaker, where the CSV files used for training and validation should be formatted accordingly. The first column should contain the labels for each entry, and the subsequent columns should contain the features.*\n",
    "\n",
    "More info about common data formats for training [here](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f00ace1-205f-4d69-a04d-3bc3dbe7f362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_train = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/train_data.csv',\n",
    "    content_type='csv'\n",
    ")\n",
    "\n",
    "s3_validate = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/test_data.csv',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9f988-ad2c-4a9a-8056-960b9cd99d22",
   "metadata": {},
   "source": [
    "In the context of Amazon SageMaker, the `estimator.fit()` method initiates a *training job* on the cloud infrastructure, using the machine specifications defined in the estimator configuration (i.e., `ml.m5.large` in this case). This method call leverages the setup previously defined by the Estimator object, including the choice of machine learning algorithm, the AWS compute instance type, and other training parameters. By passing a dictionary with keys `'train'` and `'validation'`, the method is directed to use the specified S3 locations for training and validation data, respectively. During a training job, [you are only billed for the time spent training](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html#:~:text=You%20are%20billed%20for%20the%20time%20interval%20between%20the%20value%20of%20TrainingStartTime%20and%20this%20time.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df75d237-a8b6-4443-9f05-3826ee98d1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-02-06-15-44-14-363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:44:14 Starting - Starting the training job...\n",
      "2024-02-06 15:44:30 Starting - Preparing the instances for training......\n",
      "2024-02-06 15:45:36 Downloading - Downloading input data......\n",
      "2024-02-06 15:46:26 Downloading - Downloading the training image.....\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:21.582 ip-10-0-128-70.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:21.603 ip-10-0-128-70.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Failed to parse hyperparameter objective value multi:softmax to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:22:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:22:INFO] Train matrix has 121 rows and 4 columns\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:22:INFO] Validation matrix has 31 rows\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.004 ip-10-0-128-70.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.004 ip-10-0-128-70.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.005 ip-10-0-128-70.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.005 ip-10-0-128-70.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-02-06:15:47:22:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[15:47:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.020 ip-10-0-128-70.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-02-06 15:47:22.023 ip-10-0-128-70.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[0]#011train-mlogloss:0.74046#011validation-mlogloss:0.75377\u001b[0m\n",
      "\u001b[34m[1]#011train-mlogloss:0.53122#011validation-mlogloss:0.53905\u001b[0m\n",
      "\u001b[34m[2]#011train-mlogloss:0.39538#011validation-mlogloss:0.39999\u001b[0m\n",
      "\u001b[34m[3]#011train-mlogloss:0.30241#011validation-mlogloss:0.30634\u001b[0m\n",
      "\u001b[34m[4]#011train-mlogloss:0.23618#011validation-mlogloss:0.24704\u001b[0m\n",
      "\u001b[34m[5]#011train-mlogloss:0.18671#011validation-mlogloss:0.19806\u001b[0m\n",
      "\u001b[34m[6]#011train-mlogloss:0.15040#011validation-mlogloss:0.17002\u001b[0m\n",
      "\u001b[34m[7]#011train-mlogloss:0.12433#011validation-mlogloss:0.14284\u001b[0m\n",
      "\u001b[34m[8]#011train-mlogloss:0.10282#011validation-mlogloss:0.12423\u001b[0m\n",
      "\u001b[34m[9]#011train-mlogloss:0.08655#011validation-mlogloss:0.11100\u001b[0m\n",
      "\n",
      "2024-02-06 15:47:39 Training - Training image download completed. Training in progress.\n",
      "2024-02-06 15:47:39 Uploading - Uploading generated training model\n",
      "2024-02-06 15:47:39 Completed - Training job completed\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "    'train': s3_train,\n",
    "    'validation': s3_validate\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ad4ab-87a9-4d53-b831-7505519eea77",
   "metadata": {},
   "source": [
    "In the following snippet, the `estimator.deploy()` method is used to deploy the trained model to an endpoint on Amazon SageMaker, making it available for **real-time predictions**. This deployment process involves specifying the configuration for the endpoint:\n",
    "\n",
    "- `initial_instance_count=1`: This specifies that one instance of the specified type will be used to host the model. This is typically sufficient for development or light production workloads.\n",
    "- `instance_type='ml.t2.medium'`: This sets the type of the AWS compute instance that will serve the model. You can consult the available instance types and their pricing [here](https://aws.amazon.com/sagemaker/pricing/). Also make sure that you have a [service quota](https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html) for endpoint creation.\n",
    "- `endpoint_name='iris-endpoint'`: This assigns a unique name to the endpoint, allowing it to be easily identified and accessed for making predictions.\n",
    "- `serializer=CSVSerializer()`: This parameter specifies how input data should be serialized before being sent to the model for inference. The CSVSerializer converts input data into CSV format, which is required by many of SageMaker's built-in algorithms like the XGBoost.\n",
    "\n",
    "The deploy method effectively creates a fully managed, scalable endpoint for your model, abstracting away the infrastructure management and allowing you to focus on consuming the model's predictions. Once deployed, the predictor object can be used to make real-time predictions by sending data to the iris-endpoint and receiving the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a4e520-09c1-4f4c-b785-aec761e73f88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-02-06-15-47-56-749\n",
      "INFO:sagemaker:Creating endpoint-config with name iris-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name iris-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    "    endpoint_name='iris-endpoint',\n",
    "    serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe702cb-e109-4a95-baf8-f0b5d7281076",
   "metadata": {},
   "source": [
    "The `predict()`method on is used to generate predictions based on a set of input features. By default, if a deserializer was not specified when creating the endpoint, the endpoint will return the prediction response in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dee7acd-4c54-470d-b44a-dc434955f835",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'2.0\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([7.2, 3, 6, 1.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21123ed7-555d-4ec4-9101-f2906437ec03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([7.2, 3, 6, 1.6]).decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5f150-3052-41fe-937a-e3ecdb5f2e0b",
   "metadata": {},
   "source": [
    "**IMPORTANT!**\n",
    "\n",
    "When you deploy a model to an endpoint in Amazon SageMaker using the `estimator.deploy()` method, as shown in the code snippet, **the deployed endpoint is live and incurs charges until you explicitly shut it down**. While the code assigns the live endpoint to a variable named predictor, it's important to understand the lifecycle and cost implications of such a deployment.\n",
    "\n",
    "The endpoint, once deployed, continues to run and serve inference requests until it is manually stopped. To avoid incurring unnecessary charges, you should delete the endpoint when it is no longer needed. There are two primary ways to shut down a SageMaker endpoint:\n",
    "\n",
    "1. Programmatically deleting the endpoint by calling the `delete_endpoint()` method on the predictor object.\n",
    "2. Using the AWS Management Console, navigating to SageMaker service, then go to the \"Inference\" section and select \"Endpoints\". From there, you can find the endpoint you wish to delete, select it, and click the \"Delete\" action.\n",
    "\n",
    "![Delete endpoint via the AWS Management Console](./img/delete_endpoint.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb90d72-c8f9-4ca1-a6d0-296e10571ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: iris-endpoint\n",
      "INFO:sagemaker:Deleting endpoint with name: iris-endpoint\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c461f15-0c2a-4433-b738-a27c9cce5830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
