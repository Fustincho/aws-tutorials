{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87eaf55-d888-4db8-a2bd-dd76bbb6ee8c",
   "metadata": {},
   "source": [
    "\n",
    "Amazon SageMaker Pipelines enable the creation and management of automated workflows for machine learning models. By defining steps and organizing them logically, SageMaker Pipelines streamline the process of building, training, tuning, and deploying machine learning models at scale. These steps can encompass a wide range of tasks, from data preparation and processing to model training and deployment.\n",
    "\n",
    "In Unit Two, we will continue building on the foundation established in unit 1 by reloading the essential components and configurations necessary for working with Amazon SageMaker. This includes importing the SageMaker library and essential utility functions, initializing the SageMaker session, and retrieving crucial configurations such as the AWS role ARN and S3 bucket details through helper functions. We will also reuse the XGBoost Docker image to ensure consistency in our environment setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e09a8b-bf2a-40f1-8519-e7729c1fb01e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from utils.helpers import get_secret\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_secret('role_arn')\n",
    "s3_bucket_uri = get_secret('s3_bucket_uri')\n",
    "s3_bucket_name = get_secret('s3_bucket_name')\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve('xgboost',\n",
    "                                          region='us-east-1',\n",
    "                                          version='1.5-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab7047-e57d-4e46-b61c-76164b5a7f07",
   "metadata": {},
   "source": [
    "In Unit 1, we utilized the `upload_dataset_to_s3` function to upload the Iris dataset to Amazon S3. This dataset serves as a foundational element for our machine learning tasks with Amazon SageMaker. If you haven't already executed the following lines in your environment, please do so before proceeding further in this unit:\n",
    "\n",
    "```python\n",
    "from utils.helpers import upload_dataset_to_s3\n",
    "dataset_name = 'iris'\n",
    "upload_dataset_to_s3(dataset_name, s3_bucket_name)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb222c0d-cbb6-495d-8a49-2fec7ac47bde",
   "metadata": {
    "tags": []
   },
   "source": [
    "Initializing a PipelineSession with `pipeline_session = PipelineSession()` from the `sagemaker.workflow.pipeline_context` module equips you with a specialized session designed for Amazon SageMaker Pipelines. This session extends the standard SageMaker `Session`, adding functionalities tailored for managing machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd82954-ce54-423f-9e7c-824123ac372d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2da9a1-c505-4ee5-b406-92ede97e68de",
   "metadata": {},
   "source": [
    "Configuring an `Estimator` with `sagemaker_session=pipeline_session` customizes it for SageMaker Pipelines integration. This approach renders the estimator *\"pipeline-aware\"*, enhancing its compatibility with pipeline-specific features such as resource optimization, seamless execution dependencies, artifact management, and support for conditional executions and parallelism. The rest of the following snippet is identical to unit 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2b5bc9-946d-4ad6-9ff8-374e789d445e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    num_round=10\n",
    ")\n",
    "\n",
    "s3_train = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/train_data.csv',\n",
    "    content_type='csv'\n",
    ")\n",
    "\n",
    "s3_validate = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/test_data.csv',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e2e34-c4ef-41a2-bc19-88b79c7a6da7",
   "metadata": {},
   "source": [
    "We'll explore a basic yet fundamental workflow within SageMaker Pipelines, starting with two primary steps: `TrainingStep` and `ModelStep`. \n",
    "\n",
    "![Basic pipeline](./img/basic_pipeline.png)\n",
    "\n",
    "The objective here is straightforward but fundamental in the machine learning lifecycle:\n",
    "\n",
    "- `TrainingStep`: This step involves training a machine learning model using the provided dataset and chosen algorithm within SageMaker. The training process adjusts the model's parameters to minimize the error in predictions, effectively learning from the training data.\n",
    "\n",
    "- `ModelStep`: Following the successful training of the model, the next step is to register this model within SageMaker's Model Registry. **The Model Registry is a centralized repository for managing models, where each model version is tracked, cataloged, and versioned**. Automating the transition from training to registration ensures that once a model is trained, it can be easily and systematically stored, versioned, and later retrieved for deployment or further analysis.\n",
    "\n",
    "More information about all available pipeline steps is found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df75d237-a8b6-4443-9f05-3826ee98d1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='training-step',\n",
    "    step_args=estimator.fit({\n",
    "                'train': s3_train,\n",
    "                'validation': s3_validate\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981fef3-9dca-4b8d-af75-2d6b4f365d13",
   "metadata": {},
   "source": [
    "As the warning indicates, defining a `TrainingStep` within the pipeline doesn't immediately start a training job as calling `estimator.fit()` outside of a pipeline does (Unit 1). Instead, it specifies a part of the workflow for later execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba2772-3369-4e10-bd6a-e1df85327537",
   "metadata": {},
   "source": [
    "The `Model` class is used to represent a machine learning model. Here are some of the key functionalities:\n",
    "\n",
    "- **Model Artifacts:** It allows you to specify the location of the model artifacts. These are the output of your training job, stored in Amazon S3.\n",
    "\n",
    "- **Inference Code:** You can define the Docker image that contains your inference code. This can be a default image provided by SageMaker for common machine learning frameworks (like TensorFlow, PyTorch, MXNet, etc.) or a custom Docker image that you have created.\n",
    "\n",
    "- **Environment Variables:** The class allows you to set environment variables that your inference code might need for execution.\n",
    "\n",
    "- **Execution Role:** You specify an AWS IAM role that SageMaker assumes to perform tasks on your behalf, such as accessing your model artifacts and Docker images in S3 and ECR respectively.\n",
    "\n",
    "- **Deploy:** One of the most important functionalities is deploying your model to an endpoint. This involves creating an instance (or instances) of the model, which can then be used to perform real-time or batch predictions.\n",
    "\n",
    "- **Endpoint Configuration:** When deploying a model, you can specify the type and number of instances that you want to use for the endpoint, enabling you to scale your inference according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e3f8f2-45f4-49c5-8120-558dd5423dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ace6d3-a2cc-40da-9a79-d9007bfce599",
   "metadata": {},
   "source": [
    "`training_step.properties.ModelArtifacts.S3ModelArtifacts` is a reference used in Amazon SageMaker Pipelines to dynamically access the S3 location of the model artifacts generated by a training step. When you define a TrainingStep in a SageMaker Pipeline, it trains a model and outputs artifacts, such as the trained model parameters, to a specified S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc74e7-ac9c-4b1b-b1b5-bc4374144007",
   "metadata": {},
   "source": [
    "The `register` [method](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.register) is used to register a model in the SageMaker Model Registry. The Model Registry is a centralized repository for managing models, allowing you to catalog, version, and manage models systematically across your organization. By registering a model, you can track its versions, metadata, and lineage, which facilitates model governance, auditing, and collaboration among teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c143ff-d3bd-40bd-88c7-741edaf35fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "register_params = {\n",
    "    'model_package_group_name': 'iris-classification-group',\n",
    "    'description': 'XGBoost model for Iris classification',\n",
    "    'image_uri': image_uri,\n",
    "    'task': 'CLASSIFICATION'\n",
    "}\n",
    "\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name='register-model-step',\n",
    "    step_args=model.register(**register_params)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d54c78-637a-496b-81c0-cff90d0eee28",
   "metadata": {},
   "source": [
    "The Pipeline object from sagemaker.workflow.pipeline is utilized to assemble these steps into a coherent workflow, facilitating the automation of model training and registration. It requires the pipeline name and the steps that compose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f08175-c743-4c71-8157-8ce778cdab16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name='iris-classification-model-pipeline',\n",
    "    steps=[training_step, register_model_step]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dee899-7fa2-4ec3-a3dd-479aae42b388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parallelism_config={\n",
    "    'MaxParallelExecutionSteps': 5\n",
    "}\n",
    "\n",
    "pipeline.create(\n",
    "    role_arn=role,\n",
    "    parallelism_config=parallelism_config,\n",
    "    tags=[\n",
    "        {'Key': 'Project', 'Value': 'AWSTutorials'},\n",
    "        {'Key': 'Environment', 'Value': 'Development'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eba339-8870-47d2-a076-7fa5b95bf7e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "    pipeline = Pipeline('iris-classification-model-pipeline', sagemaker_session=session)\n",
    "\n",
    "    pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6078eae-2cf2-454f-86d2-244ebca010d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.start(\n",
    "    execution_display_name='pipeline-execution',\n",
    "    execution_description='First Pipeline Execution'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0ccbd-27ab-4541-b8ae-3ae987cd1502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffc0a1-3172-4a9c-9fd1-9c6f0d5027ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call to list model packages\n",
    "response = sm_client.list_model_packages(ModelPackageGroupName='iris-classification-group')\n",
    "\n",
    "# Print the list of model packages\n",
    "for model_package in response['ModelPackageSummaryList']:\n",
    "    print(f\"Model Package Group Name: {model_package['ModelPackageGroupName']}\")\n",
    "    print(f\"Model Package ARN: {model_package['ModelPackageArn']}\")\n",
    "    print(f\"Model Package Version: {model_package.get('ModelPackageVersion', 'N/A')}\")\n",
    "    print(f\"Model Package Status: {model_package['ModelPackageStatus']}\")\n",
    "    print(\"------\")\n",
    "\n",
    "model_package_arn = response['ModelPackageSummaryList'][0]['ModelPackageArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130d9fc-bd12-4f13-8ce5-07a87b774e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "model = ModelPackage(role=role, \n",
    "                     model_package_arn=model_package_arn, \n",
    "                     sagemaker_session=session)\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                     instance_type='ml.t2.medium',\n",
    "                     endpoint_name='iris-endpointss',\n",
    "                     serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee7acd-4c54-470d-b44a-dc434955f835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_two.predict([7.2, 3, 6, 1.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21123ed7-555d-4ec4-9101-f2906437ec03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.predict([7.2, 3, 6, 1.6]).decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1036132-a7b1-4dc8-a1aa-254896e762a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor_two = sagemaker.Predictor(\n",
    "    endpoint_name=\"iris-endpoints\",\n",
    "    serializer=CSVSerializer(),  # Adjust this based on the input your model expects\n",
    "    deserializer=JSONDeserializer(),  # Adjust this based on the output format of your model\n",
    "    sagemaker_session=session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb90d72-c8f9-4ca1-a6d0-296e10571ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc232610-6833-4c95-ad13-02d713a114d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97df88-6658-4da2-8f05-bc70d1faec38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterString,\n",
    "    ParameterInteger\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "training_dataset_path = ParameterString(\n",
    "    name='Training_Set_Path',\n",
    "    default_value='train_data.csv'\n",
    ")\n",
    "\n",
    "s3_train = TrainingInput(\n",
    "    s3_data=Join(\n",
    "    on='/',\n",
    "    values=[\n",
    "        s3_bucket_uri,\n",
    "        'iris_dataset',\n",
    "        training_dataset_path\n",
    "        ]\n",
    "    ),\n",
    "    content_type='csv'\n",
    ")\n",
    "\n",
    "s3_validate = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/test_data.csv',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d74e8d-1347-43bf-9b53-958a3c9a45b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "max_depth_param = ParameterInteger(name=\"max_depth\",\n",
    "                                   default_value=5)\n",
    "objective_param = ParameterString(name=\"objective\",\n",
    "                                  default_value='multi:softmax')\n",
    "num_class_param = ParameterInteger(name=\"num_class\",\n",
    "                                   default_value=3)\n",
    "num_round_param = ParameterInteger(name=\"num_round\",\n",
    "                                   default_value=10)\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    max_depth=max_depth_param,\n",
    "    objective=objective_param,\n",
    "    num_class=num_class_param,\n",
    "    num_round=num_round_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914d932-3f84-44a2-8702-0ffc7f70709e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training step\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='training-step',\n",
    "    step_args=estimator.fit({\n",
    "                'train': s3_train,\n",
    "                'validation': s3_validate\n",
    "    })\n",
    ")\n",
    "\n",
    "# Register step\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "register_params = {\n",
    "    'model_package_group_name': 'iris-classification-group',\n",
    "    'description': 'XGBoost model for Iris classification',\n",
    "    'image_uri': image_uri,\n",
    "    'task': 'CLASSIFICATION'\n",
    "}\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name='register-model-step',\n",
    "    step_args=model.register(**register_params)\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name='iris-pipeline-with-params',\n",
    "    steps=[training_step, register_model_step],\n",
    "    parameters=[\n",
    "        max_depth_param,\n",
    "        objective_param,\n",
    "        num_class_param,\n",
    "        num_round_param,\n",
    "        training_dataset_path\n",
    "    ]\n",
    ")\n",
    "\n",
    "parallelism_config = {\n",
    "    'MaxParallelExecutionSteps': 5\n",
    "}\n",
    "\n",
    "pipeline.create(\n",
    "    role_arn=role,\n",
    "    parallelism_config=parallelism_config,\n",
    "    tags=[\n",
    "        {'Key': 'Project', 'Value': 'AWSTutorials'},\n",
    "        {'Key': 'Environment', 'Value': 'Development'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.start(\n",
    "    execution_display_name='pipeline-execution',\n",
    "    execution_description='First Pipeline Execution'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e64907-175a-436a-9e7f-1ef61c3bf9b9",
   "metadata": {},
   "source": [
    "custom_parameter_values = {\n",
    "    'max_depth': 1,\n",
    "    'num_round': 50\n",
    "}\n",
    "\n",
    "# Start the pipeline execution with custom parameters\n",
    "execution = pipeline.start(\n",
    "    parameters=custom_parameter_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20445062-434f-4aa1-b1ba-56633d4f1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation:accuracy\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef05c03-b8a3-4fc7-abed-f2461dc83c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    max_depth=max_depth_param,\n",
    "    objective=objective_param,\n",
    "    num_class=num_class_param,\n",
    "    num_round=num_round_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474fe4d-b66c-4295-92ef-f8ee5f9d81af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(eval_metric='merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a767fd-8dd5-473b-8076-e9490e71c8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fe29b-9196-4c27-9bdd-bab23b091bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "\n",
    "# Training step\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='training-step',\n",
    "    step_args=estimator.fit({\n",
    "                'train': s3_train,\n",
    "                'validation': s3_validate\n",
    "    })\n",
    ")\n",
    "\n",
    "# Register step\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "register_params = {\n",
    "    'model_package_group_name': 'iris-classification-group',\n",
    "    'description': 'XGBoost model for Iris classification',\n",
    "    'image_uri': image_uri,\n",
    "    'task': 'CLASSIFICATION'\n",
    "}\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name='register-model-step',\n",
    "    step_args=model.register(**register_params)\n",
    ")\n",
    "\n",
    "# Fail Step\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name='iris_fail',\n",
    "    error_message='What a bad model!'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1808dd-6504-415b-b62a-8313dfc3ee7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30da983-2f92-49eb-8a2d-b5b1ea8a5c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThan\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name='condition-step',\n",
    "    conditions=[\n",
    "        ConditionLessThan(\n",
    "            left=training_step.properties.FinalMetricDataList['validation:merror'].Value,\n",
    "            right=0.04\n",
    "    )],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111f218-2964-40ed-99c6-e397e6bb0175",
   "metadata": {},
   "source": [
    "AND conditions work by adding more than one condition to conditions\n",
    "\n",
    "Pipeline steps cannot have duplicate names. In addition, steps added in \"\n",
    "    209         \"the ConditionStep cannot be added in the Pipeline steps list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33e654-ad68-409c-bb10-53b3c45fdd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name='iris-pipeline-with-conditionsssssa',\n",
    "    steps=[training_step,\n",
    "           condition_step],\n",
    "    parameters=[\n",
    "        max_depth_param,\n",
    "        objective_param,\n",
    "        num_class_param,\n",
    "        num_round_param,\n",
    "        training_dataset_path\n",
    "    ]\n",
    ")\n",
    "\n",
    "parallelism_config = {\n",
    "    'MaxParallelExecutionSteps': 5\n",
    "}\n",
    "\n",
    "pipeline.create(\n",
    "    role_arn=role,\n",
    "    parallelism_config=parallelism_config,\n",
    "    tags=[\n",
    "        {'Key': 'Project', 'Value': 'AWSTutorials'},\n",
    "        {'Key': 'Environment', 'Value': 'Development'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.start(\n",
    "    execution_display_name='pipeline-execution',\n",
    "    execution_description='First Pipeline Execution'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f77066f-a0d5-432e-a4a0-709db6073a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth':IntegerParameter(1, 10, scaling_type = 'Auto')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8f055ba4-601e-41bf-b895-a3c10508cca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=f\"{s3_bucket_uri}/pipelines-output\",\n",
    "    sagemaker_session=session,\n",
    "    hyperparameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 3,\n",
    "        'num_round': 10,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9d0c9-cfbd-4811-8f69-1cf6d8d5f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst#learning-task-parameters\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "959ca8cb-bdbc-4d1b-9edd-14885dc0144f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name='validation:merror',\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    strategy='Random',\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=5,\n",
    "    objective_type='Minimize'\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_train = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/train_data.csv',\n",
    "    content_type='csv'\n",
    ")\n",
    "\n",
    "s3_validate = TrainingInput(\n",
    "    s3_data=f's3://{s3_bucket_name}/iris_dataset/test_data.csv',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0c29b243-8946-45c9-84e2-5b15c6635a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-xgboost-240202-2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................!\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuner.fit({\n",
    "                'train': s3_train,\n",
    "                'validation': s3_validate\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c2332-ed1d-47f1-9613-3aa210658866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "tuning_step = TuningStep(\n",
    "    name='tuning-step',\n",
    "    step_args=hyperparameter_tuner.fit({\n",
    "                'train': s3_train,\n",
    "                'validation': s3_validate\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fefd199b-30d5-44a9-bc4f-417d58edd02f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-xgboost-240202-1538-009-0dabc260\n",
      "sagemaker-xgboost-240202-1538-008-8a3c0002\n",
      "sagemaker-xgboost-240202-1538-007-e83f0c53\n",
      "sagemaker-xgboost-240202-1538-006-97667870\n",
      "sagemaker-xgboost-240202-1538-005-f54bebdf\n",
      "sagemaker-xgboost-240202-1538-004-ba999ca6\n",
      "sagemaker-xgboost-240202-1538-003-6600f871\n",
      "sagemaker-xgboost-240202-1538-002-2821cbd9\n",
      "sagemaker-xgboost-240202-1538-001-6833b07c\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuning_job_name = 'sagemaker-xgboost-240202-1538'\n",
    "\n",
    "tuning_job_result = HyperparameterTuningJobAnalytics(tuning_job_name, sagemaker_session=session)\n",
    "\n",
    "# Fetch the training job summaries\n",
    "job_summaries = tuning_job_result.training_job_summaries()\n",
    "\n",
    "# List the names of the training jobs\n",
    "for summary in job_summaries:\n",
    "    print(summary['TrainingJobName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f60f0-1abc-43f1-aaad-718fdd8921a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e00c0-4a57-4159-9363-dfddd12b3fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
